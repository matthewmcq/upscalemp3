{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthewmcq/upscalemp3/blob/main/LSTM_ResUNet_small.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHzW7BwGuldN",
        "outputId": "23d6afb4-02b4-4927-c7ba-39ac72c475c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# from google.colab import files\n",
        "# files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNmdKSkNUapI"
      },
      "outputs": [],
      "source": [
        "\n",
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "if not os.path.exists('audiofiles/data'):\n",
        "  os.makedirs('audiofiles/data')\n",
        "if not os.path.exists('audiofiles/data/mp3'):\n",
        "  os.makedirs('audiofiles/data/mp3')\n",
        "if not os.path.exists('audiofiles/data/wav'):\n",
        "  os.makedirs('audiofiles/data/wav')\n",
        "if not os.path.exists('coeffs'):\n",
        "  os.makedirs('coeffs')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "shutil.unpack_archive('/content/drive/MyDrive/audiofiles/output_mp3.zip', '/content/audiofiles/data/mp3')\n",
        "shutil.unpack_archive('/content/drive/MyDrive/audiofiles/output_wav.zip', '/content/audiofiles/data/wav')\n",
        "#shutil.unpack_archive('/content/drive/MyDrive/audiofiles/data/mp3_50.zip', '/content/audiofiles/data/mp3')\n",
        "#shutil.unpack_archive('/content/drive/MyDrive/audiofiles/data/wav_50.zip', '/content/audiofiles/data/wav')"
      ],
      "metadata": {
        "id": "-RaGn06xiXPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4KwTxtLfAbp",
        "outputId": "c741208f-f8a5-448f-a6d1-62de983799ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: tensorflow\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "Successfully installed tensorflow-2.15.0.post1\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KiexnXUpvMFX"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "from tqdm import tqdm\n",
        "import soundfile as sf\n",
        "#import tqdm\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K64P8tGcuRWV"
      },
      "outputs": [],
      "source": [
        "from pickleshare import pickle\n",
        "\n",
        "def save_audios(original_audio, difference_audio, summed_audio, reconstructed_audio, mp3_audio,\n",
        "                original_path, difference_path, summed_path, recon_path, mp3_path):\n",
        "    sf.write(original_path, original_audio, 44100)\n",
        "    sf.write(difference_path, difference_audio, 44100)\n",
        "    sf.write(summed_path, summed_audio, 44100)\n",
        "    sf.write(recon_path, reconstructed_audio, 44100)\n",
        "    sf.write(mp3_path, mp3_audio, 44100)\n",
        "\n",
        "def visualize_results(original_audio, predicted_audio, difference_audio, recon_audio, mp3_audio):\n",
        "    plt.figure(figsize=(18, 12))\n",
        "\n",
        "    # 1. Original Spectrogram\n",
        "    plt.subplot(4, 4, 1)\n",
        "    plt.title(\"Original Spectrogram\")\n",
        "    D_original = librosa.amplitude_to_db(np.abs(librosa.stft(original_audio)), ref=np.max)\n",
        "    im1 = plt.imshow(D_original, aspect='auto', origin='lower')\n",
        "    plt.colorbar(im1)\n",
        "    plt.subplot(4, 4, 2)\n",
        "    plt.title(\"upscaled mp3 Spectrogram\")\n",
        "    D_original = librosa.amplitude_to_db(np.abs(librosa.stft(mp3_audio)), ref=np.max)\n",
        "    im1 = plt.imshow(D_original, aspect='auto', origin='lower')\n",
        "    plt.colorbar(im1)\n",
        "\n",
        "    # 2. Predicted Spectrogram\n",
        "    plt.subplot(4, 4, 3)\n",
        "    plt.title(\"Model Predicted Spectrogram\")\n",
        "    D_predicted = librosa.amplitude_to_db(np.abs(librosa.stft(recon_audio)), ref=np.max)\n",
        "    im2 = plt.imshow(D_predicted, aspect='auto', origin='lower')\n",
        "    plt.colorbar(im2)\n",
        "    plt.subplot(4, 4, 4)\n",
        "    plt.title(\"Summed Spectrogram\")\n",
        "    D_predicted = librosa.amplitude_to_db(np.abs(librosa.stft(predicted_audio)), ref=np.max)\n",
        "    im2 = plt.imshow(D_predicted, aspect='auto', origin='lower')\n",
        "    plt.colorbar(im2)\n",
        "\n",
        "    # 3. Difference Spectrogram\n",
        "    plt.subplot(4, 4, 10)\n",
        "    plt.title(\"Difference Spectrogram\")\n",
        "    D_difference = librosa.amplitude_to_db(np.abs(librosa.stft(difference_audio)), ref=np.max)\n",
        "    im3 = plt.imshow(D_difference, aspect='auto', origin='lower')\n",
        "    plt.colorbar(im3)\n",
        "\n",
        "    # 4. Original Waveform\n",
        "    plt.subplot(4, 4, 5)\n",
        "    plt.title(\"True Waveform\")\n",
        "    plt.plot(original_audio)\n",
        "\n",
        "    # 5. Predicted Waveform\n",
        "    plt.subplot(4, 4, 6)\n",
        "    plt.title(\"Reconstructed Waveform\")\n",
        "    plt.plot(predicted_audio)\n",
        "\n",
        "\n",
        "    # 7. Summed Waveform\n",
        "    plt.subplot(4, 4, 7)\n",
        "    plt.title(\"Predicted Difference between true wav and upscaled mp3\")\n",
        "    plt.plot(recon_audio)\n",
        "\n",
        "    # 8. read diff\n",
        "    plt.subplot(4, 4, 8)\n",
        "    plt.title(\"Difference between true wav and upscaled mp3\")\n",
        "    plt.plot(original_audio - mp3_audio)\n",
        "\n",
        "    # 7. our diff\n",
        "    plt.subplot(4, 4, 9)\n",
        "    plt.title(\"Real Diff Spectrogram\")\n",
        "    D_original = librosa.amplitude_to_db(np.abs(librosa.stft(original_audio - mp3_audio)), ref=np.max)\n",
        "    im1 = plt.imshow(D_original, aspect='auto', origin='lower')\n",
        "    plt.colorbar(im1)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "filenames = set()\n",
        "DATA_LEN = 4000\n",
        "\n",
        "def get_spectrogram_from_folders(filepath_mp3, filepath_wav, n_fft, hop_length, chunk_index, DATA_LEN=4000):\n",
        "\n",
        "    start_index = chunk_index * DATA_LEN\n",
        "    end_index = start_index + DATA_LEN\n",
        "\n",
        "    mp3_files = sorted([f for f in os.listdir(filepath_mp3) if f.endswith(\".mp3\")])\n",
        "\n",
        "    # Select files for the current chunk\n",
        "    mp3_files_chunk = mp3_files[start_index:end_index]\n",
        "\n",
        "    magnitudes_mp3 = []\n",
        "    phases_mp3 = []\n",
        "    magnitudes_wav = []\n",
        "    phases_wav = []\n",
        "\n",
        "    pbar = tqdm(total=DATA_LEN, desc=\"Processing MP3 files\")\n",
        "    if True:\n",
        "      for filename in mp3_files:\n",
        "      #for i, filename in enumerate(mp3_files):\n",
        "          if len(magnitudes_mp3) == DATA_LEN:\n",
        "            break\n",
        "\n",
        "          if filename in filenames:\n",
        "            continue\n",
        "          try:\n",
        "              audio_mp3, original_sr = librosa.load(os.path.join(filepath_mp3, filename), sr=44100)\n",
        "\n",
        "              #TRY TURNING THIS ON\n",
        "              audio_mp3_resampled = librosa.resample(audio_mp3, orig_sr=original_sr, target_sr=44100)\n",
        "              if len(audio_mp3_resampled) < 44100:\n",
        "                  continue\n",
        "                  #raise Exception(f\"Audio file {filename} is too short.\")\n",
        "              S_mp3 = librosa.stft(audio_mp3_resampled, n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "              filename_as_wav = filename[:-4] + \".wav\"\n",
        "              if filename_as_wav in os.listdir(filepath_wav):\n",
        "                  audio_wav, sr = librosa.load(os.path.join(filepath_wav, filename_as_wav), sr=44100)\n",
        "                  audio_wav_resampled = librosa.resample(audio_wav, orig_sr=sr, target_sr=44100)\n",
        "                  if len(audio_wav_resampled) < 44100:\n",
        "                      continue\n",
        "                      #raise Exception(f\"Audio file {filename_as_wav} is too short.\")\n",
        "\n",
        "                  S_wav = librosa.stft(audio_wav_resampled, n_fft=n_fft, hop_length=hop_length)\n",
        "\n",
        "                  magnitudes_mp3.append(np.abs(S_mp3))\n",
        "                  phases_mp3.append(np.angle(S_mp3))\n",
        "                  magnitudes_wav.append(np.abs(S_wav))\n",
        "                  phases_wav.append(np.angle(S_wav))\n",
        "                  filenames.add(filename)\n",
        "                  pbar.update(len(magnitudes_mp3) - pbar.n)\n",
        "              else:\n",
        "                  print(f\"WAV version of {filename} not found.\")\n",
        "                  i -= 1\n",
        "                  continue\n",
        "\n",
        "          except Exception as e:\n",
        "              print(f\"Error processing {filename}: {e}\")\n",
        "              filenames.add(filename)\n",
        "              continue\n",
        "\n",
        "    pbar.close()\n",
        "    print(\"unifying mp3 dimensions\")\n",
        "    magnitudes_mp3, phases_mp3 = unify_dimensions(magnitudes_mp3, phases_mp3)\n",
        "    print(\"unifying wav dimensions\")\n",
        "    magnitudes_wav, phases_wav = unify_dimensions(magnitudes_wav, phases_wav)\n",
        "    # Save to google drive with path /content/drive/MyDrive/audiofiles/{data_segment_i}\n",
        "\n",
        "    # np.save(f'/content/drive/MyDrive/audiofiles/mp3_magnitudes_chunk_{chunk_index}.npy', magnitudes_mp3)\n",
        "    # np.save(f'/content/drive/MyDrive/audiofiles/mp3_phases_chunk_{chunk_index}.npy', phases_mp3)\n",
        "    # np.save(f'/content/drive/MyDrive/audiofiles/wav_magnitudes_chunk_{chunk_index}.npy', magnitudes_wav)\n",
        "    # np.save(f'/content/drive/MyDrive/audiofiles/wav_phases_chunk_{chunk_index}.npy', phases_wav)\n",
        "\n",
        "    return magnitudes_mp3, phases_mp3, magnitudes_wav, phases_wav\n",
        "\n",
        "def unif_pad_array(arr, max_time, max_freq):\n",
        "        time_pad_length = max_time - arr.shape[1]\n",
        "        freq_pad_length = max_freq - arr.shape[0]\n",
        "        return np.pad(arr, ((0, freq_pad_length), (0, time_pad_length)))\n",
        "\n",
        "def unify_dimensions(magnitudes, phases):\n",
        "    max_time_length = max([mag.shape[1] for mag in magnitudes + phases])\n",
        "    max_freq_length = max([mag.shape[0] for mag in magnitudes + phases])\n",
        "    print(max_time_length, max_freq_length)\n",
        "\n",
        "    unified_mags = []\n",
        "    #for mag in tqdm(magnitudes, desc=\"Processing Magnitudes\"):\n",
        "    for mag in magnitudes:\n",
        "        mag_padded = unif_pad_array(mag, max_time_length, max_freq_length)\n",
        "        unified_mags.append(mag_padded)\n",
        "\n",
        "    unified_phases = []\n",
        "    #for phase in tqdm(phases, desc=\"Processing Phases\"):\n",
        "    for phase in phases:\n",
        "        phase_padded = unif_pad_array(phase, max_time_length, max_freq_length)\n",
        "        unified_phases.append(phase_padded)\n",
        "\n",
        "    print(unified_mags[0].shape)\n",
        "    print(\"Converting to numpy arrays and returning\")\n",
        "    return np.array(unified_mags), np.array(unified_phases)\n",
        "\n",
        "\n",
        "def compute_min_max(arr, is_phase=False):\n",
        "    \"\"\"Compute min and max for the array.\"\"\"\n",
        "    if not is_phase:\n",
        "        arr = np.log1p(abs(arr))\n",
        "    min_val = np.min(arr)\n",
        "    max_val = np.max(arr)\n",
        "    return min_val, max_val\n",
        "\n",
        "def denormalize_with_given_min_max(arr, min_val, max_val, is_phase=False):\n",
        "    \"\"\"Denormalize the array using given min and max and return the denormalized array.\"\"\"\n",
        "    arr = arr * (max_val - min_val) + min_val\n",
        "    if not is_phase:\n",
        "        arr = np.expm1(arr)  # inverse of log1p\n",
        "    return arr\n",
        "\n",
        "\n",
        "\n",
        "def denormalize_data(pred_mag_norm, true_mag_norm, pred_phase_norm, true_phase_norm, mag_min_val, mag_max_val):\n",
        "    # Denormalize magnitude\n",
        "    pred_mag = denormalize_with_given_min_max(pred_mag_norm, mag_min_val, mag_max_val)\n",
        "    true_mag = denormalize_with_given_min_max(true_mag_norm, mag_min_val, mag_max_val)\n",
        "\n",
        "    # Denormalize phase\n",
        "    pred_phase = denormalize_phase(pred_phase_norm)\n",
        "    true_phase = denormalize_phase(true_phase_norm)\n",
        "\n",
        "    return pred_mag, true_mag, pred_phase, true_phase\n",
        "\n",
        "def normalize_with_given_min_max(arr, min_val, max_val, is_phase=False):\n",
        "    \"\"\"Normalize the array using given min and max and return the normalized array.\"\"\"\n",
        "    if not is_phase:\n",
        "        arr = np.log1p(np.abs(arr))\n",
        "    return (arr - min_val) / (max_val - min_val)\n",
        "\n",
        "def normalize_phase(arr):\n",
        "    \"\"\"Normalize phase values to the range [0, 1] from [-π, π].\"\"\"\n",
        "    return (arr + np.pi) / (2 * np.pi)\n",
        "\n",
        "def denormalize_phase(arr):\n",
        "    \"\"\"Denormalize phase values from the range [0, 1] to [-π, π].\"\"\"\n",
        "    return arr * 2 * np.pi - np.pi\n",
        "\n",
        "def normalize_data(combined_mp3, combined_wav, load_data=False):\n",
        "    # if load_data:\n",
        "    #     print(\"loading normalized data\")\n",
        "    #     pred_mag = np.load(\"coeffs/pred_mag_normalized.npy\", allow_pickle=True)\n",
        "    #     true_mag = np.load(\"coeffs/true_mag_normalized.npy\", allow_pickle=True)\n",
        "    #     return pred_mag, true_mag\n",
        "    pred_min = np.min(combined_mp3[..., 0])\n",
        "    pred_max = np.max(combined_mp3[..., 0])\n",
        "\n",
        "\n",
        "    # Normalize based on global min and max\n",
        "    pred_mag = normalize_with_given_min_max(combined_mp3[..., 0], pred_min, pred_max)\n",
        "    true_mag = normalize_with_given_min_max(combined_wav[..., 0], pred_min, pred_max)\n",
        "\n",
        "    # print(\"saving normalized pred data\")\n",
        "    # np.save(\"coeffs/pred_mag_normalized.npy\", pred_mag)\n",
        "    # print(\"saving normalized true data\")\n",
        "    # np.save(\"coeffs/true_mag_normalized.npy\", true_mag)\n",
        "    # Normalize phase\n",
        "    pred_phase = normalize_phase(combined_mp3[..., 1])\n",
        "    true_phase = normalize_phase(combined_wav[..., 1])\n",
        "\n",
        "    return pred_mag, true_mag, pred_phase, true_phase\n",
        "\n",
        "def comb_pad_array(arr, max_time, max_freq):\n",
        "        time_pad_length = max_time - arr.shape[1]\n",
        "        freq_pad_length = max_freq - arr.shape[0]\n",
        "        return np.pad(arr, ((0, freq_pad_length), (0, time_pad_length)))\n",
        "\n",
        "\n",
        "def wrapped_phase_difference(phase1, phase2):\n",
        "          diff = tf.abs(phase1 - phase2)\n",
        "          return tf.minimum(diff, 1.0 - diff)\n",
        "def combine_magnitude_phase( magnitudes_mp3, phases_mp3, load_spectrograms=False):\n",
        "    # if load_spectrograms:\n",
        "    #     print(\"loading combined coefficients\")\n",
        "    #     combined_wav = np.load(\"coeffs/combined_wav.npy\", allow_pickle=True)\n",
        "    #     combined_mp3 = np.load(\"coeffs/combined_mp3.npy\", allow_pickle=True)\n",
        "    #     return combined_wav, combined_mp3\n",
        "\n",
        "    print(\"Finding max lengths for padding\")\n",
        "    max_freq_length, max_time_length = max(\n",
        "        (mag.shape[0], mag.shape[1]) for mag in\n",
        "        (*magnitudes_mp3, *phases_mp3)\n",
        "    )\n",
        "    print(max_time_length, max_freq_length)\n",
        "\n",
        "    #combined_wav = []\n",
        "    combined_mp3 = []\n",
        "\n",
        "    #for mag, phase in tqdm(zip(magnitudes_wav, phases_wav), total=len(magnitudes_wav), desc=\"Processing WAV\"):\n",
        "    # for mag, phase in zip(magnitudes_wav, phases_wav):\n",
        "    #     mag_padded = comb_pad_array(mag, max_time_length, max_freq_length)\n",
        "    #     phase_padded = comb_pad_array(phase, max_time_length, max_freq_length)\n",
        "    #     combined_wav.append(np.stack([mag_padded, phase_padded], axis=-1))\n",
        "\n",
        "    #for mag, phase in tqdm(zip(magnitudes_mp3, phases_mp3), total=len(magnitudes_mp3), desc=\"Processing MP3\"):\n",
        "    for mag, phase in zip(magnitudes_mp3, phases_mp3):\n",
        "        mag_padded = comb_pad_array(mag, max_time_length, max_freq_length)\n",
        "        phase_padded = comb_pad_array(phase, max_time_length, max_freq_length)\n",
        "        combined_mp3.append(np.stack([mag_padded, phase_padded], axis=-1))\n",
        "\n",
        "    print(\"Converting to numpy arrays\")\n",
        "    #combined_wav = np.array(combined_wav)\n",
        "    combined_mp3 = np.array(combined_mp3)\n",
        "    # print(\"saving combined coefficients\")\n",
        "    # np.save(\"coeffs/combined_wav.npy\", combined_wav)\n",
        "    # print(\"saved combined wav\")\n",
        "    # np.save(\"coeffs/combined_mp3.npy\", combined_mp3)\n",
        "    # print(\"saved combined mp3\")\n",
        "    return combined_mp3 #, combined_wav\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v971mmAG-25a"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def normalize(y):\n",
        "    \"\"\"Normalize a numpy array to the range [0, 1].\"\"\"\n",
        "    y_min, y_max = y.min(), y.max()\n",
        "    if y_max == y_min:\n",
        "        # Avoid division by zero\n",
        "        return np.ones_like(y)\n",
        "    return (y - y_min) / (y_max - y_min)\n",
        "\n",
        "\n",
        "def extrapolate_frequency_content(data, boundary=700, degree=3, decay_rate=0.999, load_data=False):\n",
        "    if load_data:\n",
        "      print(\"loading transients\")\n",
        "      modified_data = np.load(\"coeffs/transients.npy\", allow_pickle=True)\n",
        "      return modified_data\n",
        "\n",
        "    magnitude = data[..., 0]\n",
        "    phase = data[..., 1]\n",
        "\n",
        "    modified_magnitude = np.copy(magnitude)\n",
        "    modified_phase = np.copy(phase)\n",
        "\n",
        "\n",
        "\n",
        "    for i in tqdm(range(magnitude.shape[0]), total=magnitude.shape[0], desc=\"adding frequencies to transients\"):  # Iterate over examples\n",
        "        for j in range(magnitude.shape[2]):  # Iterate over frames\n",
        "            frame_magnitude = magnitude[i, :, j]\n",
        "\n",
        "            # Get known lower frequencies and their indices\n",
        "            x = np.arange(boundary)\n",
        "            y = frame_magnitude[:boundary]\n",
        "\n",
        "            # Fit a polynomial to the known data\n",
        "            coeffs = np.polyfit(x, y, degree)\n",
        "            polynomial = np.poly1d(coeffs)\n",
        "\n",
        "            # Extrapolate to the higher frequency bins\n",
        "            x_high = np.arange(boundary, magnitude.shape[1])\n",
        "            y_high = polynomial(x_high)\n",
        "\n",
        "            # Normalize the extrapolated values to [0, 1]\n",
        "            y_high_normalized = normalize(y_high)\n",
        "\n",
        "            # Determine the starting magnitude for exponential decay\n",
        "            avg_bins = 16\n",
        "            start_magnitude = np.max(frame_magnitude[boundary-avg_bins:boundary])\n",
        "            y_high_masked = y_high_normalized * start_magnitude\n",
        "            decay_length = len(y_high_masked)\n",
        "            decay_factor = np.power(decay_rate, np.arange(decay_length))\n",
        "\n",
        "            # Apply the decay to the extrapolated values\n",
        "            y_high_masked *= decay_factor\n",
        "\n",
        "\n",
        "            # Update the frame with the masked extrapolated values\n",
        "            condition = modified_magnitude[i, boundary:, j] != 0  # Identify non-zero values\n",
        "            avg_values = (modified_magnitude[i, boundary:, j] + y_high_masked) / 2  # Compute average values\n",
        "\n",
        "            modified_magnitude[i, boundary:, j] = np.where(condition, avg_values, y_high_masked)\n",
        "\n",
        "\n",
        "    modified_phase = phase\n",
        "    # Combine magnitude and modified phase (phase remains unchanged)\n",
        "    modified_data = np.stack([modified_magnitude, modified_phase], axis=-1)\n",
        "    # print(\"saving extended transients\")\n",
        "    # np.save(\"coeffs/transients.npy\", modified_data)\n",
        "    # print(\"saved modified data\")\n",
        "    return modified_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "n_fft = 2048\n",
        "hop_length = 256\n",
        "\n",
        "# 1. Load and preprocess data\n",
        "mp3_folder = \"/content/audiofiles/data/mp3/output_mp3\"\n",
        "wav_folder = \"/content/audiofiles/data/wav/output_wav\"\n",
        "\n",
        "# After Quitting session, must change load_spectrograms and load_unified to False\n",
        "# After first init change back to True\n",
        "total_files = len([f for f in os.listdir(mp3_folder) if f.endswith(\".mp3\")])\n",
        "total_chunks = (total_files + DATA_LEN - 1) // DATA_LEN  # Calculate how many chunks are needed\n"
      ],
      "metadata": {
        "id": "dpus_8aEbe-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "zV5EHdFquRWY",
        "outputId": "b9eedfa9-3ca9-4d9b-fee9-02ff65533e08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing chunk 1/15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing MP3 files:   0%|          | 0/4000 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-9157a77f29ff>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing chunk {chunk_index + 1}/{total_chunks}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     magnitudes_mp3, phases_mp3, magnitudes_wav, phases_wav = get_spectrogram_from_folders(\n\u001b[0m\u001b[1;32m      5\u001b[0m         mp3_folder, wav_folder, n_fft, hop_length, chunk_index, DATA_LEN)\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-3b8462ed39bb>\u001b[0m in \u001b[0;36mget_spectrogram_from_folders\u001b[0;34m(filepath_mp3, filepath_wav, n_fft, hop_length, chunk_index, DATA_LEN)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m               \u001b[0maudio_mp3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_sr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_mp3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m44100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m               \u001b[0;31m#TRY TURNING THIS ON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;31m# Final cleanup for dtype and contiguity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_mono\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mto_mono\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    502\u001b[0m     \"\"\"\n\u001b[1;32m    503\u001b[0m     \u001b[0;31m# Validate the buffer.  Stereo is ok here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m     \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lazy_loader/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattr_to_modules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0msubmod_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{package_name}.{attr_to_modules[name]}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0msubmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmod_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/util/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0mnopython\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m )\n\u001b[0;32m-> 1063\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_localmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m     \u001b[0;34m\"\"\"Vectorized wrapper for the localmax stencil\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_localmax_sten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/decorators.py\u001b[0m in \u001b[0;36mwrap\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mguvec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGUVectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfty\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mftylist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mguvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mftylist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mguvec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/gufunc.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, fty)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgufunc_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_ufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/ufuncbuilder.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, sig)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mtargetoptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargetoptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         cres, args, return_type = _compile_element_wise_function(\n\u001b[0m\u001b[1;32m    259\u001b[0m             self.nb_func, targetoptions, sig)\n\u001b[1;32m    260\u001b[0m         \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_finalize_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/ufuncbuilder.py\u001b[0m in \u001b[0;36m_compile_element_wise_function\u001b[0;34m(nb_func, targetoptions, sig)\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# Do compilation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Return CompileResult to test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0mcres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtargetoptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/ufuncbuilder.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, sig, locals, **targetoptions)\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_looplift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compile_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/np/ufunc/ufuncbuilder.py\u001b[0m in \u001b[0;36m_compile_core\u001b[0;34m(self, sig, flags, locals)\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0;31m# Compile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                     cres = compiler.compile_extra(typingctx, targetctx,\n\u001b[0m\u001b[1;32m    158\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                                                   \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(typingctx, targetctx, func, args, return_type, flags, locals, library, pipeline_class)\u001b[0m\n\u001b[1;32m    768\u001b[0m     pipeline = pipeline_class(typingctx, targetctx, library,\n\u001b[1;32m    769\u001b[0m                               args, return_type, flags, locals)\n\u001b[0;32m--> 770\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_extra\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36mcompile_extra\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlifted_from\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_bytecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_ir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36m_compile_bytecode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    527\u001b[0m         \"\"\"\n\u001b[1;32m    528\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_ir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36m_compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    493\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                     \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/compiler_machinery.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mpass_inst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pass_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpass_inst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpass_inst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompilerPass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_runPass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpass_inst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Legacy pass in use\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/compiler_machinery.py\u001b[0m in \u001b[0;36m_runPass\u001b[0;34m(self, index, pss, internal_state)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_initialization\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mSimpleTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpass_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m                 \u001b[0mmutated\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mSimpleTimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfinalize_time\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0mmutated\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_finalizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minternal_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/compiler_machinery.py\u001b[0m in \u001b[0;36mcheck\u001b[0;34m(func, compiler_state)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiler_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m             \u001b[0mmangled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompiler_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmangled\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m                 msg = (\"CompilerPass implementations should return True/False. \"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/typed_passes.py\u001b[0m in \u001b[0;36mrun_pass\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    464\u001b[0m                 lower = self.lowering_class(targetctx, library, fndesc, interp,\n\u001b[1;32m    465\u001b[0m                                             metadata=metadata)\n\u001b[0;32m--> 466\u001b[0;31m                 \u001b[0mlower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_cpython_wrapper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                     \u001b[0mlower\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_cpython_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease_gil\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/lowering.py\u001b[0m in \u001b[0;36mlower\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator_info\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenlower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower_normal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfndesc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenlower\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeneratorLower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/lowering.py\u001b[0m in \u001b[0;36mlower_normal_function\u001b[0;34m(self, fndesc)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Init argument values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_function_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mentry_block_tail\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower_function_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;31m# Close tail of entry block, do not emit debug metadata else the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/lowering.py\u001b[0m in \u001b[0;36mlower_function_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_at_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"# lower block: {offset}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mentry_block_tail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/lowering.py\u001b[0m in \u001b[0;36mlower_block\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m    283\u001b[0m             with new_error_context('lowering \"{inst}\" at {loc}', inst=inst,\n\u001b[1;32m    284\u001b[0m                                    loc=self.loc, errcls_=defaulterrcls):\n\u001b[0;32m--> 285\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower_inst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/lowering.py\u001b[0m in \u001b[0;36mlower_inst\u001b[0;34m(self, inst)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAssign\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             \u001b[0mty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower_assign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m             \u001b[0margidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;31m# If this is a store from an arg, like x = arg.x then tell debuginfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/lowering.py\u001b[0m in \u001b[0;36mlower_assign\u001b[0;34m(self, ty, inst)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower_expr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/lowering.py\u001b[0m in \u001b[0;36mlower_expr\u001b[0;34m(self, resty, expr)\u001b[0m\n\u001b[1;32m   1209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1212\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/lowering.py\u001b[0m in \u001b[0;36mlower_call\u001b[0;34m(self, resty, expr)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lower_call_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;31m# If lowering the call returned None, interpret that as returning dummy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/lowering.py\u001b[0m in \u001b[0;36m_lower_call_normal\u001b[0;34m(self, fnty, expr, signature)\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0margvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mthe_self\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, builder, args, loc)\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_imp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_linking_libs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'libs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loc'\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# drop unused loc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m             \u001b[0;31m# Copy the following attributes from the wrapped.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/stencils/stencil.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, context, builder, sig, args)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         cres = self.stencilFunc.compile_for_argtys(sig.args, {},\n\u001b[0m\u001b[1;32m     31\u001b[0m                     sig.return_type, None)\n\u001b[1;32m     32\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfndesc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/stencils/stencil.py\u001b[0m in \u001b[0;36mcompile_for_argtys\u001b[0;34m(self, argtys, kwtys, return_type, sigret)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;31m# look in the type cache to find if result array is passed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypemap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalltypes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margtys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         new_func = self._stencil_wrapper(result, sigret, return_type,\n\u001b[0m\u001b[1;32m    371\u001b[0m                                          typemap, calltypes, *argtys)\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/stencils/stencil.py\u001b[0m in \u001b[0;36m_stencil_wrapper\u001b[0;34m(self, result, sigret, return_type, typemap, calltypes, *args)\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;31m# body in it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         \u001b[0mir_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfixup_var_define_in_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstencil_ir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m         new_func = compiler.compile_ir(\n\u001b[0m\u001b[1;32m    759\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typingctx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targetctx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36mcompile_ir\u001b[0;34m(typingctx, targetctx, func_ir, args, return_type, flags, locals, lifted, lifted_from, is_lifted_loop, library, pipeline_class)\u001b[0m\n\u001b[1;32m    831\u001b[0m         pipeline = pipeline_class(typingctx, targetctx, library,\n\u001b[1;32m    832\u001b[0m                                   args, return_type, flags, locals)\n\u001b[0;32m--> 833\u001b[0;31m         return pipeline.compile_ir(func_ir=func_ir, lifted=lifted,\n\u001b[0m\u001b[1;32m    834\u001b[0m                                    lifted_from=lifted_from)\n\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36mcompile_ir\u001b[0;34m(self, func_ir, lifted, lifted_from)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0mFixupArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdefine_pipelines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36m_compile_ir\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \"\"\"\n\u001b[1;32m    535\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_ir\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/compiler.py\u001b[0m in \u001b[0;36m_compile_core\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    493\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m                     \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/compiler_machinery.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mpass_inst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pass_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpass_inst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpass_inst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCompilerPass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_runPass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpass_inst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Legacy pass in use\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/compiler_lock.py\u001b[0m in \u001b[0;36m_acquire_compile_lock\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_acquire_compile_lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/compiler_machinery.py\u001b[0m in \u001b[0;36m_runPass\u001b[0;34m(self, index, pss, internal_state)\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0mqualname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqualname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minternal_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minternal_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minternal_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minternal_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/pprint.py\u001b[0m in \u001b[0;36mpformat\u001b[0;34m(object, indent, width, depth, compact, sort_dicts, underscore_numbers)\u001b[0m\n\u001b[1;32m     60\u001b[0m     return PrettyPrinter(indent=indent, width=width, depth=depth,\n\u001b[1;32m     61\u001b[0m                          \u001b[0mcompact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompact\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_dicts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_dicts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                          underscore_numbers=underscore_numbers).pformat(object)\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_dicts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/pprint.py\u001b[0m in \u001b[0;36mpformat\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0msio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_StringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/pprint.py\u001b[0m in \u001b[0;36m_format\u001b[0;34m(self, object, stream, indent, allowance, context, level)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_readable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0mmax_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_width\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mallowance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_width\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/pprint.py\u001b[0m in \u001b[0;36m_repr\u001b[0;34m(self, object, context, level)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         repr, readable, recursive = self.format(object, context.copy(),\n\u001b[0m\u001b[1;32m    455\u001b[0m                                                 self._depth, level)\n\u001b[1;32m    456\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreadable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/pprint.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mrepresents\u001b[0m \u001b[0ma\u001b[0m \u001b[0mrecursive\u001b[0m \u001b[0mconstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \"\"\"\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pprint_default_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[0;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[1;32m    583\u001b[0m                 krepr, kreadable, krecur = self.format(\n\u001b[1;32m    584\u001b[0m                     k, context, maxlevels, level)\n\u001b[0;32m--> 585\u001b[0;31m                 vrepr, vreadable, vrecur = self.format(\n\u001b[0m\u001b[1;32m    586\u001b[0m                     v, context, maxlevels, level)\n\u001b[1;32m    587\u001b[0m                 \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkrepr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvrepr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/pprint.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mobject\u001b[0m \u001b[0mrepresents\u001b[0m \u001b[0ma\u001b[0m \u001b[0mrecursive\u001b[0m \u001b[0mconstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         \"\"\"\n\u001b[0;32m--> 467\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_safe_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pprint_default_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/pprint.py\u001b[0m in \u001b[0;36m_safe_repr\u001b[0;34m(self, object, context, maxlevels, level)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0m_dispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUserString\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_pprint_user_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_safe_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;31m# Return triple (repr_string, isreadable, isrecursive).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "for chunk_index in range(0, total_chunks):\n",
        "    gc.collect()\n",
        "    print(f\"Processing chunk {chunk_index + 1}/{total_chunks}\")\n",
        "    magnitudes_mp3, phases_mp3, magnitudes_wav, phases_wav = get_spectrogram_from_folders(\n",
        "        mp3_folder, wav_folder, n_fft, hop_length, chunk_index, DATA_LEN)\n",
        "\n",
        "    combined_wav = combine_magnitude_phase(magnitudes_wav, phases_wav, load_spectrograms=False)\n",
        "    del magnitudes_wav, phases_wav\n",
        "\n",
        "    combined_mp3 = combine_magnitude_phase(magnitudes_mp3, phases_mp3, load_spectrograms=False)\n",
        "    del magnitudes_mp3, phases_mp3\n",
        "\n",
        "    total_samples = combined_wav.shape[0]\n",
        "    samples_to_select = total_samples\n",
        "\n",
        "    # Create an array of all indices\n",
        "    all_indices = np.arange(total_samples)\n",
        "\n",
        "    # Randomly select indices without replacement\n",
        "    selected_indices = np.random.choice(total_samples, samples_to_select, replace=False)\n",
        "\n",
        "    combined_wav = combined_wav[selected_indices]\n",
        "    combined_mp3 = combined_mp3[selected_indices]\n",
        "\n",
        "    combined_mp3 = extrapolate_frequency_content(combined_mp3, load_data=False)\n",
        "\n",
        "    pred_mag, true_mag, pred_phase, true_phase = normalize_data(combined_mp3, combined_wav, load_data=False)\n",
        "    print(\"Finished normalizing data\")\n",
        "    combined_mp3[..., 0] = pred_mag\n",
        "    combined_wav[..., 0] = true_mag\n",
        "    combined_mp3[..., 1] = pred_phase\n",
        "    combined_wav[..., 1] = true_phase\n",
        "\n",
        "    np.save(f'/content/drive/MyDrive/audiofiles/combined_wav_chunk_{chunk_index}.npy', combined_wav)\n",
        "    np.save(f'/content/drive/MyDrive/audiofiles/combined_mp3_chunk_{chunk_index}.npy', combined_mp3)\n",
        "\n",
        "print(\"Finished loading spectrograms and Processing Data\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pHAjn39euRWY"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_data_chunk(chunk_index):\n",
        "    path_wav = f'/content/drive/MyDrive/audiofiles/combined_wav_chunk_{chunk_index}.npy'\n",
        "    path_mp3 = f'/content/drive/MyDrive/audiofiles/combined_mp3_chunk_{chunk_index}.npy'\n",
        "    combined_wav = np.load(path_wav, allow_pickle=True)\n",
        "    combined_mp3 = np.load(path_mp3, allow_pickle=True)\n",
        "    return combined_mp3, combined_wav\n",
        "\n",
        "def get_dataset(combined_mp3, combined_wav, batch_size=1):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((combined_mp3, combined_wav))\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fj__rYIuRWY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmPE9J5dN5Ks",
        "outputId": "95892b2b-3596-4f8f-f04d-a2b01fa6459b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.3.2)\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I_mfptr_L4t",
        "outputId": "4bef9760-4084-4576-e45d-19ec8f05c203"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "adding frequencies to transients: 100%|██████████| 8000/8000 [07:09<00:00, 18.61it/s]\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72hZcq3xuRWY",
        "outputId": "14aca4e8-1d10-48c2-9118-8cf625bf5232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished normalizing data\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTwSyOLQuRWY"
      },
      "outputs": [],
      "source": [
        "\n",
        "@tf.keras.utils.register_keras_serializable()\n",
        "class DynamicResizeLayer(tf.keras.layers.Layer):\n",
        "    def call(self, inputs, target_shape):\n",
        "        # Resize the input to the target shape\n",
        "        return tf.image.resize(inputs, size=(target_shape[1], target_shape[2]))\n",
        "    def get_config(self):\n",
        "        # Return an empty config dictionary since this layer has no configurable parameters\n",
        "        return {}\n",
        "\n",
        "def log_spectral_distance():\n",
        "    def loss(y_true, y_pred):\n",
        "        # Extract the first channel for magnitude\n",
        "        y_true_mag = y_true[..., 0:1]\n",
        "        y_pred_mag = y_pred[..., 0:1]\n",
        "\n",
        "        # Calculate the difference per item\n",
        "        diff_per_item = y_true_mag - y_pred_mag\n",
        "\n",
        "        norm_per_item = tf.norm(diff_per_item, axis=[1, 2])\n",
        "\n",
        "        # Compute the mean of these norms\n",
        "        mean_norm = tf.reduce_mean(norm_per_item)\n",
        "\n",
        "        return mean_norm\n",
        "\n",
        "    return loss\n",
        "\n",
        "def scaled_tanh(x):\n",
        "    return (tf.math.tanh(x) + 1) / 2\n",
        "\n",
        "def UResNet():\n",
        "    def residual_encoder_block(input_tensor, n_filters, kernel_size=3, batchnorm=True, activation=\"prelu\", strides=(1,1)):\n",
        "        x = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size),\n",
        "                                  kernel_initializer=\"he_normal\", padding=\"same\", strides=strides)(input_tensor)\n",
        "        if batchnorm:\n",
        "            x = tf.keras.layers.BatchNormalization()(x)\n",
        "        if activation == \"relu\":\n",
        "            x = tf.keras.layers.ReLU()(x)\n",
        "        elif activation == \"prelu\":\n",
        "            # Instantiate PReLU layer\n",
        "            prelu = tf.keras.layers.PReLU()\n",
        "            x = prelu(x)\n",
        "\n",
        "        x = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size),\n",
        "                                  kernel_initializer=\"he_normal\", padding=\"same\")(x)\n",
        "        if batchnorm:\n",
        "            x = tf.keras.layers.BatchNormalization()(x)\n",
        "        if activation == \"relu\":\n",
        "            x = tf.keras.layers.ReLU()(x)\n",
        "        elif activation == \"prelu\":\n",
        "            # Instantiate PReLU layer\n",
        "            prelu = tf.keras.layers.PReLU()\n",
        "            x = prelu(x)\n",
        "\n",
        "        shortcut = tf.keras.layers.Conv2D(filters=n_filters, kernel_size=(1,1),\n",
        "                                          strides=strides, padding=\"same\")(input_tensor)\n",
        "        if batchnorm:\n",
        "            shortcut = tf.keras.layers.BatchNormalization()(shortcut)\n",
        "\n",
        "        x = tf.keras.layers.Add()([x, shortcut])\n",
        "        if batchnorm:\n",
        "            x = tf.keras.layers.BatchNormalization()(x)\n",
        "        if activation == \"relu\":\n",
        "            x = tf.keras.layers.ReLU()(x)\n",
        "        elif activation == \"prelu\":\n",
        "            # Instantiate PReLU layer\n",
        "            prelu = tf.keras.layers.PReLU()\n",
        "            x = prelu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def decoder_block(input_tensor, skip_tensor, n_filters, kernel_size=3, batchnorm=True, activation=\"relu\"):\n",
        "        x = tf.keras.layers.Conv2DTranspose(filters=n_filters, kernel_size=(3, 3), strides=(2, 2), padding=\"same\")(input_tensor)\n",
        "\n",
        "        # Use a Lambda layer to get the dynamic shape\n",
        "        dynamic_shape = tf.keras.layers.Lambda(lambda x: tf.shape(x))(x)\n",
        "\n",
        "        # Custom layer for dynamic resizing\n",
        "        dynamic_resize_layer = DynamicResizeLayer()\n",
        "        skip_tensor_resized = dynamic_resize_layer(skip_tensor, dynamic_shape)\n",
        "\n",
        "        x = tf.keras.layers.concatenate([skip_tensor_resized, x], axis=-1)\n",
        "        x = residual_encoder_block(x, n_filters, kernel_size, batchnorm)\n",
        "        return x\n",
        "\n",
        "    def process_with_lstm(tensor):\n",
        "        # Extract spatial dimensions and channels\n",
        "        height, width, channels = tensor.shape[1], tensor.shape[2], tensor.shape[3]\n",
        "\n",
        "        # Reshape for LSTM: Treat width as timesteps, height * channels as features\n",
        "        x = tf.keras.layers.Reshape((width, height * channels))(tensor)\n",
        "\n",
        "        # Apply LSTM\n",
        "        x = tf.keras.layers.LSTM(height * width, return_sequences=True)(x)\n",
        "\n",
        "        # Calculate the new number of channels for reshaping\n",
        "        # The total number of elements in the output shape should match input\n",
        "        new_channels = 1\n",
        "\n",
        "        # Reshape back to a 3D tensor\n",
        "        x = tf.keras.layers.Reshape((height, width, new_channels))(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    inputs = tf.keras.layers.Input(shape=(1025,173,2))\n",
        "    original_phase = tf.keras.layers.Lambda(lambda x: x[..., 1:])(inputs)\n",
        "    x_mag = tf.keras.layers.Lambda(lambda x: x[..., 0:])(inputs)\n",
        "\n",
        "    x_mag = tf.keras.layers.Conv2D(64, (3, 3), activation=None, padding='same')(x_mag)\n",
        "    x_mag = tf.keras.layers.PReLU()(x_mag)\n",
        "    x_mag = tf.keras.layers.BatchNormalization()(x_mag)\n",
        "\n",
        "    x_mag_lstm = process_with_lstm(x_mag)\n",
        "    # Encoder (Downsampling) - Magnitude\n",
        "    c1_mag = residual_encoder_block(x_mag_lstm, 64, strides=2)\n",
        "\n",
        "    # lstm_units_c1_mag = 44631\n",
        "    c1_mag_lstm = process_with_lstm(c1_mag)\n",
        "\n",
        "    c2_mag = residual_encoder_block(c1_mag, 128, strides=2)\n",
        "\n",
        "    # lstm_units_c2_mag = 11308\n",
        "    c2_mag_lstm = process_with_lstm(c2_mag)\n",
        "\n",
        "    c3_mag = residual_encoder_block(c2_mag, 256, strides=2)\n",
        "\n",
        "\n",
        "    c3_mag_lstm = process_with_lstm(c3_mag)\n",
        "\n",
        "    c4_mag = residual_encoder_block(c3_mag, 512, strides=2)\n",
        "\n",
        "    c4_mag_lstm = process_with_lstm(c4_mag)\n",
        "\n",
        "    c5_mag = residual_encoder_block(c4_mag, 1024, strides=2)\n",
        "\n",
        "    c5_mag_lstm = process_with_lstm(c5_mag)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Decoder blocks: Use *_lstm outputs in skip connections\n",
        "    u5_mag = decoder_block(c5_mag_lstm, c4_mag_lstm, 1024)\n",
        "    u4_mag = decoder_block(u5_mag, c3_mag_lstm, 512)\n",
        "    u3_mag = decoder_block(u4_mag, c2_mag_lstm, 256)\n",
        "    u2_mag = decoder_block(u3_mag, c1_mag_lstm, 128)\n",
        "    u1_mag = decoder_block(u2_mag, x_mag_lstm, 64)  # using x_mag directly here\n",
        "\n",
        "    # Output layer - Magnitude\n",
        "    output_mag = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(u1_mag)\n",
        "\n",
        "\n",
        "    desired_shape = (1025, 173)\n",
        "\n",
        "    # Cropping the magnitude output\n",
        "    output_mag_cropped = tf.keras.layers.Lambda(\n",
        "        lambda x: tf.image.crop_to_bounding_box(x,\n",
        "                                                offset_height=0,\n",
        "                                                offset_width=0,\n",
        "                                                target_height=desired_shape[0],\n",
        "                                                target_width=desired_shape[1])\n",
        "    )(output_mag)\n",
        "\n",
        "\n",
        "    combined_output_cropped = tf.keras.layers.Concatenate(axis=-1)([output_mag_cropped, original_phase])\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=[inputs], outputs=[combined_output_cropped])\n",
        "    model.compile(optimizer='adam', loss=log_spectral_distance(), metrics=['accuracy',tf.keras.metrics.MeanSquaredError()])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "# EarlyStopping callback\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',   # Metric to monitor, usually val_loss or val_accuracy\n",
        "    patience=10,           # Number of epochs with no improvement after which training will be stopped\n",
        "    verbose=1,            # When set to 1, it prints a message when stopping\n",
        "    restore_best_weights=True # Restores model weights from the epoch with the best value of the monitored quantity\n",
        ")\n",
        "\n",
        "def train_model():\n",
        "    ResNet = UResNet()\n",
        "    print(\"Model Built\")\n",
        "\n",
        "    print(\"Starting fitting\")\n",
        "    # Include the EarlyStopping callback in the fit method\n",
        "    for chunk_index in range(total_chunks):\n",
        "      print(f\"Loading chunk {chunk_index + 1}/{total_chunks}\")\n",
        "      combined_mp3, combined_wav = load_data_chunk(chunk_index)\n",
        "      dataset = get_dataset(combined_mp3, combined_wav)\n",
        "\n",
        "      # Assuming your model is already compiled\n",
        "      ResNet.fit(dataset, epochs=10, batch_size=1, shuffle=True)  # Set your training parameters\n",
        "\n",
        "      ResNet.save(f'/content/drive/MyDrive/upscalemodels/model_after_chunk_{chunk_index}_LSTM_ALLBLOCKS.keras')\n",
        "      ResNet.save(f'/content/drive/MyDrive/upscalemodels/model_after_chunk_{chunk_index}_LSTM_ALLBLOCKS.pb')\n",
        "\n",
        "      # Clear references\n",
        "      combined_mp3, combined_wav, dataset = None, None, None\n",
        "      gc.collect()\n",
        "      print(f\"Model saved after processing chunk {chunk_index + 1}/{total_chunks}\")\n",
        "\n",
        "    print(\"Finished fitting\")\n",
        "    return ResNet\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Initializing model\")\n",
        "ResNet = train_model()"
      ],
      "metadata": {
        "id": "YVoWPZhNlhHi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ffa26d-da2e-42e5-dc22-e811a0209f69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_FILEPATH = '/content/drive/MyDrive/upscalemodels/nfft2048_hl256_100ep_8000ex_FAT.keras'"
      ],
      "metadata": {
        "id": "ZhCQ89GRa84t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G710EJOFuRWZ"
      },
      "outputs": [],
      "source": [
        "ResNet.save(MODEL_FILEPATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "acOwxHtMuRWZ"
      },
      "outputs": [],
      "source": [
        "del ResNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BY0tixdmWCCK"
      },
      "outputs": [],
      "source": [
        "del combined_mp3, combined_wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jfBcYPJ_hpwz"
      },
      "outputs": [],
      "source": [
        "# alt_mp3 = np.load(\"coeffs/alt_mp3.npy\", allow_pickle=True)\n",
        "# alt_wav = np.load(\"coeffs/alt_wav.npy\", allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkK5ACkYOFTf"
      },
      "outputs": [],
      "source": [
        "\n",
        "# alt_mp3 = extrapolate_frequency_content(alt_mp3, load_data=False)\n",
        "# pred_mag_alt, true_mag_alt, pred_phase_alt, true_phase_alt = normalize_data(alt_mp3, alt_wav, load_data=False)\n",
        "# print(\"Finished normalizing data\")\n",
        "# alt_mp3[..., 0] = pred_mag_alt\n",
        "# alt_wav[..., 0] = true_mag_alt\n",
        "# alt_mp3[..., 1] = pred_phase_alt\n",
        "# alt_wav[..., 1] = true_phase_alt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvfHfE8KcjdY"
      },
      "outputs": [],
      "source": [
        "ResNet = tf.keras.models.load_model(MODEL_FILEPATH, safe_mode=False, custom_objects={\n",
        "    'DynamicResizeLayer': DynamicResizeLayer,\n",
        "    'loss': log_spectral_distance()  # Note: Call the function if it returns a loss function\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-PjOdjgKOU2"
      },
      "outputs": [],
      "source": [
        "# # Compile the model (if the model was saved with its training configuration,\n",
        "# # this step is not necessary)\n",
        "\n",
        "# # Training data\n",
        "# # X_new and y_new should be your new data\n",
        "\n",
        "# ResNet.compile(optimizer='adam', loss=log_spectral_distance(), metrics=['accuracy',tf.keras.metrics.MeanSquaredError()])\n",
        "# # Train the model on the new data\n",
        "# history = ResNet.fit(\n",
        "#         alt_mp3,\n",
        "#         alt_wav,\n",
        "#         validation_split=0.1,\n",
        "#         epochs=100,  # You can set a higher number since early stopping will be used\n",
        "#         batch_size=1,\n",
        "#         shuffle=True,\n",
        "#         callbacks=[early_stopping]  # Add the callback here\n",
        "#     )\n",
        "\n",
        "# # Save the updated model if needed\n",
        "# ResNet.save('/content/drive/MyDrive/upscalemodels/nfft2048_hl256_100ep_4400ex_Udepthm5_FIX_extra_training.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-bP7biauRWZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "if not os.path.exists('audiofiles/data/original'):\n",
        "  os.makedirs('audiofiles/data/original')\n",
        "if not os.path.exists('audiofiles/data/difference'):\n",
        "  os.makedirs('audiofiles/data/difference')\n",
        "if not os.path.exists('audiofiles/data/pred'):\n",
        "  os.makedirs('audiofiles/data/pred')\n",
        "if not os.path.exists('audiofiles/data/reconstructed'):\n",
        "  os.makedirs('audiofiles/data/reconstructed')\n",
        "\n",
        "# combined_mp3 = alt_mp3\n",
        "# combined_wav = alt_wav\n",
        "\n",
        "print(\"Predicting\")\n",
        "batch_size = 2\n",
        "num_samples = len(combined_mp3)\n",
        "num_batches = int(np.ceil(num_samples / batch_size))\n",
        "\n",
        "reconstructed_audios = []\n",
        "true_audios = []\n",
        "\n",
        "def denormalize_mag(arr):\n",
        "  return np.exp(arr) - 1\n",
        "\n",
        "for i in range(num_batches):\n",
        "  if i > 20:\n",
        "    break\n",
        "  start_idx = i * batch_size\n",
        "  end_idx = start_idx + batch_size\n",
        "\n",
        "  batch_mp3 = combined_mp3[start_idx:end_idx]\n",
        "  batch_wav = combined_wav[start_idx:end_idx]\n",
        "\n",
        "\n",
        "\n",
        "  differences_predicted = ResNet.predict(batch_mp3)\n",
        "  batch_pred_mag = denormalize_mag(batch_mp3[...,0])\n",
        "\n",
        "  batch_pred_phase = denormalize_phase(batch_mp3[...,1])\n",
        "  # Splitting the differences_predicted into magnitude and phase\n",
        "  differences_mag = differences_predicted[..., 0]\n",
        "  differences_phase = differences_predicted[..., 1]\n",
        "\n",
        "  # differences_mag *= magnitude_mask\n",
        "  # differences_phase *= phase_mask\n",
        "\n",
        "  # Denormalize magnitude and phase for batch_mp3\n",
        "  differences_mag = denormalize_mag(differences_mag)\n",
        "  differences_phase = denormalize_phase(differences_phase)\n",
        "\n",
        "  # Construct the denormalized batch_mp3\n",
        "\n",
        "  # Denormalize magnitude and phase for batch_wav\n",
        "  batch_true_mag = denormalize_mag(batch_wav[..., 0])\n",
        "  batch_true_phase = denormalize_phase(batch_wav[..., 1])\n",
        "\n",
        "  # Apply the predicted differences to the mp3 magnitude and phase\n",
        "\n",
        "  pre_spectrograms = batch_pred_mag * np.exp(1j * batch_pred_phase)\n",
        "  pre_audios = [librosa.istft(pre_spectrogram) for pre_spectrogram in pre_spectrograms]\n",
        "  true_spectrograms = batch_true_mag * np.exp(1j * batch_true_phase)\n",
        "  batch_true_audios = [librosa.istft(true_spectrogram) for true_spectrogram in true_spectrograms]\n",
        "  true_audios.extend(batch_true_audios)\n",
        "\n",
        "\n",
        "  model_spectrograms = differences_mag * np.exp(1j * differences_phase)\n",
        "  model_pred_audios = [librosa.istft(model_spectrogram) for model_spectrogram in model_spectrograms]\n",
        "  difference_audios = [true_audio - pred_audio for true_audio, pred_audio in zip(batch_true_audios, model_pred_audios)]\n",
        "  batch_reconstructed_audios = [pred_audio + pre_audio for pre_audio, pred_audio in zip(pre_audios, model_pred_audios)]\n",
        "  reconstructed_audios.extend(batch_reconstructed_audios)\n",
        "\n",
        "  for j, (recon_audio, diff_audio, pred_audio, mp3) in enumerate(zip(batch_reconstructed_audios,\n",
        "                                                                          difference_audios, model_pred_audios, pre_audios)):\n",
        "          idx = i * batch_size + j\n",
        "          visualize_results(true_audios[idx], recon_audio, diff_audio, pred_audio, mp3)\n",
        "          real_diff = true_audios[idx] - mp3\n",
        "          save_audios(true_audios[idx],\n",
        "                  diff_audio,\n",
        "                  pred_audio,\n",
        "                  recon_audio,\n",
        "                  mp3,\n",
        "                  f\"/content/drive/MyDrive/audiofiles/data/original/true_wav_{idx}.wav\",\n",
        "                  f\"/content/drive/MyDrive/audiofiles/data/difference/difference_{idx}.wav\",\n",
        "                  f\"/content/drive/MyDrive/audiofiles/data/pred/pred_{idx}.wav\",\n",
        "                  f\"/content/drive/MyDrive/audiofiles/data/reconstructed/reconstructed_{idx}.wav\",\n",
        "                  f\"/content/drive/MyDrive/audiofiles/data/original/mp3_{idx}.wav\")\n",
        "  # Visualization\n",
        "\n",
        "\n",
        "  i += 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1YesIUVM5X1"
      },
      "outputs": [],
      "source": [
        "#emergency indicies save\n",
        "np.save('unselected.npy', np.array(unselected_indices))\n",
        "np.save('selected.npy', np.array(selected_indices))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}